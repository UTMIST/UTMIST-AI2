{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-26T06:05:09.872757Z",
     "start_time": "2025-10-26T06:05:07.060472Z"
    }
   },
   "source": [
    "from environment.environment import CameraResolution, WarehouseBrawl\n",
    "from environment.agent import Agent, RandomAgent, UserInputAgent, ConstantAgent, run_real_time_match"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kian/Projects/UTMIST-AI2/.venv1/lib/python3.12/site-packages/pygame/pkgdata.py:25: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_stream, resource_exists\n",
      "Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
      "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
      "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T05:33:17.678317Z",
     "start_time": "2025-10-26T05:31:41.812728Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Run a match against user input (Out of the box Agent options include: UserInputAgent, ConstantAgent, RandomAgent and more in environment/agent.py\n",
    "agent_1 = UserInputAgent()\n",
    "agent_2 = RandomAgent()\n",
    "agent_3 = ConstantAgent()\n",
    "max_timesteps = 30*90\n",
    "run_real_time_match(agent_1, agent_3)"
   ],
   "id": "3683e23ee1827a0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obs space [-1, -1, -1, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, -1, 0, -1, -1, 0, -1, -1, 0, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, -1, 0, -1, -1, 0, -1, -1, 0, -1, -1, 0, -1, -1, -1, -1] [1, 1, 1, 1, 1, 1, 1, 2, 12, 1, 1, 1, 1, 3, 11, 2, 1, 1, 3, 1, 1, 3, 1, 1, 3, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 12, 1, 1, 1, 1, 3, 11, 2, 1, 1, 3, 1, 1, 3, 1, 1, 3, 1, 1, 3, 1, 1, 1, 1]\n",
      "Action space [0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Ground is rendered\n",
      "Ground is rendered\n",
      "Stage is rendered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 21.35it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 37.04it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 22.34it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 42.31it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MatchStats(match_time=90.0, player1=PlayerStats(damage_taken=0, damage_done=260, lives_left=3), player2=PlayerStats(damage_taken=260, damage_done=0, lives_left=2), player1_result=<Result.WIN: 1>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "70c1d6fea2b1b2d1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T19:02:58.548703Z",
     "start_time": "2025-10-25T19:02:57.985206Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# The following is a dissection of what happens when run_match is called\n",
    "# env is initialized and initial observations are taken\n",
    "env = WarehouseBrawl(resolution=CameraResolution.LOW, train_mode=False)\n",
    "observations, info = env.reset()\n",
    "obs_1 = observations[0]\n",
    "obs_2 = observations[1]\n",
    "\n",
    "\n",
    "platform1 = env.objects['platform1']\n",
    "\n",
    "# On each tick, platform1 is moved, actions from agents (in this case, sampling from same agent) are taken, and the environment is stepped.\n",
    "platform1.physics_process(0.05)\n",
    "full_action = {\n",
    "    0: agent_2.predict(obs_1),\n",
    "    1: agent_2.predict(obs_2),\n",
    "}\n",
    "\n",
    "observations, rewards, terminated, truncated, info = env.step(full_action)\n",
    "obs_1 = observations[0]\n",
    "obs_2 = observations[1]\n",
    "\n",
    "print(\"Observations and actions below\")\n",
    "print(f'{obs_1=}')\n",
    "print(f'{full_action=}')\n"
   ],
   "id": "d161e45f907ef4b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obs space [-1, -1, -1, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, -1, 0, -1, -1, 0, -1, -1, 0, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, -1, 0, -1, -1, 0, -1, -1, 0, -1, -1, 0, -1, -1, -1, -1] [1, 1, 1, 1, 1, 1, 1, 2, 12, 1, 1, 1, 1, 3, 11, 2, 1, 1, 3, 1, 1, 3, 1, 1, 3, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 12, 1, 1, 1, 1, 3, 11, 2, 1, 1, 3, 1, 1, 3, 1, 1, 3, 1, 1, 3, 1, 1, 1, 1]\n",
      "Action space [0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Observations and actions below\n",
      "obs_1=array([ 5.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  1.        ,  0.        ,  7.        ,  0.        ,\n",
      "       10.        ,  0.        ,  0.        ,  3.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        , -0.02427733,  1.02427733,\n",
      "       -0.72831998,  0.72831998, -5.        ,  0.        ,  0.        ,\n",
      "        0.        ,  1.        ,  0.        ,  1.        ,  0.        ,\n",
      "        7.        ,  0.        , 10.        ,  0.        ,  0.        ,\n",
      "        3.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "       -0.02427733,  1.02427733, -0.72831998,  0.72831998])\n",
      "full_action={0: array([0.8752054 , 0.43054044, 0.7024335 , 0.25002134, 0.41227365,\n",
      "       0.44131702, 0.9946157 , 0.5552907 , 0.13701501, 0.24443287],\n",
      "      dtype=float32), 1: array([0.60771155, 0.53029954, 0.437008  , 0.93546927, 0.5549245 ,\n",
      "       0.7867303 , 0.6149911 , 0.98021257, 0.6545342 , 0.13462265],\n",
      "      dtype=float32)}\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T06:05:33.760583Z",
     "start_time": "2025-10-26T06:05:33.750658Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import gymnasium as gym\n",
    "from torch.nn import functional as F\n",
    "from torch import nn as nn\n",
    "import numpy as np\n",
    "import pygame\n",
    "from stable_baselines3 import A2C, PPO, SAC, DQN, DDPG, TD3, HER\n",
    "from sb3_contrib import RecurrentPPO\n",
    "from stable_baselines3.common.base_class import BaseAlgorithm\n",
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "class MLPExtractor(BaseFeaturesExtractor):\n",
    "    '''\n",
    "    Class that defines an MLP Base Features Extractor\n",
    "    '''\n",
    "    def __init__(self, observation_space: gym.Space, features_dim: int = 64, hidden_dim: int = 64):\n",
    "        super(MLPExtractor, self).__init__(observation_space, features_dim)\n",
    "        self.model = MLPPolicy(\n",
    "            obs_dim=observation_space.shape[0],\n",
    "            action_dim=10,\n",
    "            hidden_dim=hidden_dim,\n",
    "        )\n",
    "\n",
    "    def forward(self, obs: torch.Tensor) -> torch.Tensor:\n",
    "        return self.model(obs)\n",
    "\n",
    "    @classmethod\n",
    "    def get_policy_kwargs(cls, features_dim: int = 64, hidden_dim: int = 64) -> dict:\n",
    "        return dict(\n",
    "            features_extractor_class=cls,\n",
    "            features_extractor_kwargs=dict(features_dim=features_dim, hidden_dim=hidden_dim) #NOTE: features_dim = 10 to match action space output\n",
    "        )\n",
    "\n",
    "class CustomAgent(Agent):\n",
    "    def __init__(self, sb3_class, file_path: str = None, extractor: BaseFeaturesExtractor = None):\n",
    "        self.sb3_class = sb3_class\n",
    "        self.extractor = extractor\n",
    "        super().__init__(file_path)\n",
    "\n",
    "    def _initialize(self) -> None:\n",
    "        if self.file_path is None:\n",
    "            self.model = self.sb3_class(\"MlpPolicy\", self.env, policy_kwargs=self.extractor.get_policy_kwargs(), verbose=0, n_steps=30*90*3, batch_size=128, ent_coef=0.01)\n",
    "            del self.env\n",
    "        else:\n",
    "            self.model = self.sb3_class.load(self.file_path)\n",
    "\n",
    "    def _gdown(self) -> str:\n",
    "        # Call gdown to your link\n",
    "        return\n",
    "\n",
    "    #def set_ignore_grad(self) -> None:\n",
    "        #self.model.set_ignore_act_grad(True)\n",
    "\n",
    "    def predict(self, obs):\n",
    "        action, _ = self.model.predict(obs)\n",
    "        return action\n",
    "\n",
    "    def save(self, file_path: str) -> None:\n",
    "        self.model.save(file_path, include=['num_timesteps'])\n",
    "\n",
    "    def learn(self, env, total_timesteps, log_interval: int = 1, verbose=0):\n",
    "        self.model.set_env(env)\n",
    "        self.model.verbose = verbose\n",
    "        self.model.learn(\n",
    "            total_timesteps=total_timesteps,\n",
    "            log_interval=log_interval,\n",
    "        )"
   ],
   "id": "92eeb07bbadb6a15",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T06:06:10.412381Z",
     "start_time": "2025-10-26T06:05:34.873479Z"
    }
   },
   "cell_type": "code",
   "source": [
    "agent_4 = CustomAgent(sb3_class=PPO, extractor=MLPExtractor, file_path=\"checkpoints/experiment_1/rl_model_1312200_steps.zip\")\n",
    "agent_1 = UserInputAgent()\n",
    "max_timesteps = 30*90\n",
    "run_real_time_match(agent_1, agent_4)"
   ],
   "id": "1140458a07fa0116",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obs space [-1, -1, -1, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, -1, 0, -1, -1, 0, -1, -1, 0, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, -1, 0, -1, -1, 0, -1, -1, 0, -1, -1, 0, -1, -1, -1, -1] [1, 1, 1, 1, 1, 1, 1, 2, 12, 1, 1, 1, 1, 3, 11, 2, 1, 1, 3, 1, 1, 3, 1, 1, 3, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 12, 1, 1, 1, 1, 3, 11, 2, 1, 1, 3, 1, 1, 3, 1, 1, 3, 1, 1, 3, 1, 1, 1, 1]\n",
      "Action space [0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Ground is rendered\n",
      "Ground is rendered\n",
      "Stage is rendered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 17.31it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 41.15it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 21.69it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 41.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collided Spear, True, True\n",
      "[FRAME 338] Player 1 dropped 'Spear' spawner at [4.625420730272914, -4.369060510573794] (id 2).\n",
      "collided Spear, True, True\n",
      "[FRAME 780] Player 1 dropped 'Spear' spawner at [4.540806578957974, -0.4100800030041557] (id 3).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MatchStats(match_time=27.3, player1=PlayerStats(damage_taken=0, damage_done=0, lives_left=3), player2=PlayerStats(damage_taken=0, damage_done=0, lives_left=2), player1_result=<Result.WIN: 1>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "9533fe478b07ff2d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c6e52586329a4605"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
